#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TTS è¯­éŸ³ç”Ÿæˆå·¥å…·

ä»æ–‡æœ¬æ–‡ä»¶è¯»å–å†…å®¹ï¼Œä½¿ç”¨ TTS æ¨¡å‹ç”ŸæˆæŒ‡å®šè¯­è¨€çš„è¯­éŸ³ã€‚
æ”¯æŒä½¿ç”¨éŸ³é¢‘æ ·æœ¬ä½œä¸ºå‚è€ƒè¿›è¡Œè¯­éŸ³å…‹éš†ã€‚
"""

import argparse
import os
import sys
from pathlib import Path
from typing import Optional, Any

# è‡ªåŠ¨åŒæ„ Coqui TTS æœåŠ¡æ¡æ¬¾ï¼ˆç”¨äº XTTS v2 ç­‰æ¨¡å‹ï¼‰
os.environ['COQUI_TOS_AGREED'] = '1'

from TTS.api import TTS


def get_reference_audio(audio_path: str, logger: Optional[Any] = None) -> str:
    """
    è·å–å‚è€ƒéŸ³é¢‘æ–‡ä»¶è·¯å¾„å¹¶éªŒè¯å…¶å­˜åœ¨
    
    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        logger: æ—¥å¿—è®°å½•å™¨ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        å‚è€ƒéŸ³é¢‘æ–‡ä»¶è·¯å¾„
    """
    path = Path(audio_path)
    if not path.exists():
        raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {path}")

    # æ”¯æŒçš„éŸ³é¢‘æ ¼å¼
    audio_extensions = {'.wav', '.mp3', '.flac', '.m4a', '.aac', '.ogg', '.opus'}
    file_ext = path.suffix.lower()

    # å®šä¹‰è¾“å‡ºå‡½æ•°
    def log_info(msg: str):
        if logger:
            logger.info(msg)
        else:
            print(msg)

    # éªŒè¯æ˜¯å¦ä¸ºéŸ³é¢‘æ–‡ä»¶
    if file_ext in audio_extensions:
        log_info(f"ğŸµ ä½¿ç”¨éŸ³é¢‘æ–‡ä»¶: {path}")
        return str(path)

    # æœªçŸ¥æ ¼å¼ï¼Œå°è¯•ä½œä¸ºéŸ³é¢‘æ–‡ä»¶å¤„ç†
    log_info(f"âš ï¸  æœªçŸ¥æ–‡ä»¶æ ¼å¼ ({file_ext})ï¼Œå°è¯•ä½œä¸ºéŸ³é¢‘æ–‡ä»¶ä½¿ç”¨: {path}")
    return str(path)


def get_text_from_input(input_str: str) -> str:
    """
    ä»è¾“å…¥è·å–æ–‡æœ¬ï¼Œæ”¯æŒæ–‡ä»¶è·¯å¾„æˆ–ç›´æ¥æ–‡æœ¬
    
    Args:
        input_str: æ–‡ä»¶è·¯å¾„æˆ–ç›´æ¥æ–‡æœ¬å†…å®¹
    
    Returns:
        æ–‡æœ¬å†…å®¹
    """
    input_path = Path(input_str)

    # å¦‚æœè¾“å…¥æ˜¯å­˜åœ¨çš„æ–‡ä»¶è·¯å¾„ï¼Œåˆ™ä»æ–‡ä»¶è¯»å–
    if input_path.exists() and input_path.is_file():
        # æ³¨æ„ï¼šget_text_from_input æ²¡æœ‰ logger å‚æ•°ï¼Œä¿æŒ print
        print(f"ğŸ“„ æ£€æµ‹åˆ°æ–‡ä»¶è·¯å¾„ï¼Œæ­£åœ¨è¯»å–: {input_path}")
        for encoding in ('utf-8', 'gbk'):
            try:
                with open(input_path, 'r', encoding=encoding) as f:
                    text = f.read().strip()
                if not text:
                    raise ValueError(f"æ–‡æœ¬æ–‡ä»¶ä¸ºç©º: {input_path}")
                return text
            except UnicodeDecodeError:
                continue
        raise ValueError(f"æ— æ³•è¯»å–æ–‡æœ¬æ–‡ä»¶ï¼Œè¯·ç¡®ä¿æ–‡ä»¶ä½¿ç”¨ UTF-8 æˆ– GBK ç¼–ç : {input_path}")
    else:
        # å¦åˆ™ç›´æ¥ä½œä¸ºæ–‡æœ¬ä½¿ç”¨
        text = input_str.strip()
        if not text:
            raise ValueError("è¾“å…¥çš„æ–‡æœ¬ä¸èƒ½ä¸ºç©º")
        return text


def get_available_models_by_language(language: str) -> list:
    """
    ä½¿ç”¨ TTS API åŠ¨æ€æŸ¥è¯¢æŒ‡å®šè¯­è¨€çš„å¯ç”¨æ¨¡å‹
    
    Args:
        language: è¯­è¨€ä»£ç ï¼ˆå¦‚ 'en', 'zh', 'ja', 'es' ç­‰ï¼‰
    
    Returns:
        list: è¯¥è¯­è¨€çš„å¯ç”¨æ¨¡å‹åˆ—è¡¨ï¼Œæ ¼å¼ä¸º ['tts_models/lang/dataset/model', ...]
    """
    try:
        from TTS.api import TTS
        tts = TTS()
        manager = tts.list_models()
        all_models = manager.list_tts_models()

        # æŸ¥æ‰¾åŒ¹é…è¯­è¨€çš„æ¨¡å‹
        lang_lower = language.lower()
        # è¯­è¨€ä»£ç æ˜ å°„ï¼ˆæ ‡å‡†åŒ–ï¼‰
        lang_map = {
            'zh': 'zh-CN',
            'chinese': 'zh-CN',
            'cn': 'zh-CN',
        }
        normalized_lang = lang_map.get(lang_lower, lang_lower)

        # è¿‡æ»¤å‡ºè¯¥è¯­è¨€çš„æ¨¡å‹
        matching_models = [
            model for model in all_models
            if isinstance(model, str) and f'/{normalized_lang}/' in model or f'/{lang_lower}/' in model
        ]

        return matching_models if matching_models else []
    except Exception:
        return []


def select_model(language: str, prefer_multilingual: bool = False) -> str:
    """
    æ ¹æ®è¯­è¨€è‡ªåŠ¨é€‰æ‹©æ¨¡å‹
    
    ç­–ç•¥ï¼š
    1. å¦‚æœ prefer_multilingual=Trueï¼Œç›´æ¥è¿”å› XTTS v2 å¤šè¯­è¨€æ¨¡å‹
    2. å¦åˆ™ï¼Œä¼˜å…ˆä½¿ç”¨ç»è¿‡éªŒè¯çš„ç¨³å®šå•è¯­è¨€æ¨¡å‹
    3. å¯¹äºå·²çŸ¥æœ‰é—®é¢˜çš„æ¨¡å‹ï¼ˆå¦‚ ja/kokoroï¼‰ï¼Œä½¿ç”¨ XTTS v2
    4. å¦‚æœæ²¡æœ‰å•è¯­è¨€æ¨¡å‹ï¼Œå›é€€åˆ° XTTS v2
    
    Args:
        language: è¯­è¨€ä»£ç ï¼ˆå¦‚ 'en', 'zh', 'ja' ç­‰ï¼‰
        prefer_multilingual: æ˜¯å¦ä¼˜å…ˆä½¿ç”¨å¤šè¯­è¨€æ¨¡å‹ï¼ˆé»˜è®¤ Falseï¼‰
    
    Returns:

        str: æ¨¡å‹åç§°
    """
    # å¦‚æœæ˜ç¡®è¦æ±‚ä½¿ç”¨å¤šè¯­è¨€æ¨¡å‹
    if prefer_multilingual:
        return 'tts_models/multilingual/multi-dataset/xtts_v2'

    lang_lower = language.lower()

    # ç»è¿‡éªŒè¯çš„ç¨³å®šå•è¯­è¨€æ¨¡å‹ï¼ˆå·²çŸ¥å¯ä»¥æ­£å¸¸å·¥ä½œï¼‰
    stable_single_lang_models = {
        # ä¸­æ–‡ - ç¨³å®š
        'zh': "tts_models/zh-CN/baker/tacotron2-DDC-GST",
        'ja': "'tts_models/ja/kokoro/tacotron2-DDC'",
        'chinese': "tts_models/zh-CN/baker/tacotron2-DDC-GST",
        'cn': "tts_models/zh-CN/baker/tacotron2-DDC-GST",
        'zh-cn': "tts_models/zh-CN/baker/tacotron2-DDC-GST",
        # è‹±æ–‡ - ç¨³å®š
        'en': "tts_models/en/ljspeech/tacotron2-DDC",
        'english': "tts_models/en/ljspeech/tacotron2-DDC",
        # æ³•è¯­ - ç¨³å®š
        'fr': "tts_models/fr/mai/tacotron2-DDC",
        'french': "tts_models/fr/mai/tacotron2-DDC",
        # å¾·è¯­ - ç¨³å®š
        'de': "tts_models/de/thorsten/tacotron2-DDC",
        'german': "tts_models/de/thorsten/tacotron2-DDC",
        # è¥¿ç­ç‰™è¯­ - ç¨³å®š
        'es': "tts_models/es/mai/tacotron2-DDC",
        'spanish': "tts_models/es/mai/tacotron2-DDC",
        'espaÃ±ol': "tts_models/es/mai/tacotron2-DDC",
    }

    # å·²çŸ¥æœ‰é—®é¢˜çš„è¯­è¨€ï¼ˆæ¨¡å‹æ–‡ä»¶ä¸å®Œæ•´æˆ–ä¸‹è½½å¤±è´¥ï¼‰ï¼Œç›´æ¥ä½¿ç”¨ XTTS v2
    problematic_languages = {
        'ja', 'japanese',  # kokoro æ¨¡å‹æœ‰æ–‡ä»¶ç¼ºå¤±é—®é¢˜
    }

    # å¦‚æœæ˜¯å·²çŸ¥æœ‰é—®é¢˜çš„è¯­è¨€ï¼Œä½¿ç”¨ XTTS v2
    if lang_lower in problematic_languages:
        return 'tts_models/multilingual/multi-dataset/xtts_v2'

    # å¦‚æœæœ‰ç¨³å®šçš„å•è¯­è¨€æ¨¡å‹ï¼Œä½¿ç”¨å®ƒ
    if lang_lower in stable_single_lang_models:
        return stable_single_lang_models[lang_lower]

    # å¦åˆ™ï¼Œå›é€€åˆ° XTTS v2 å¤šè¯­è¨€æ¨¡å‹
    return 'tts_models/multilingual/multi-dataset/xtts_v2'


def generate_speech(
        input_text: str,
        language: str,
        video_sample: Optional[str] = None,
        model_name: Optional[str] = None,
        output_path: Optional[str] = None,
        device: str = "cpu",
        prefer_multilingual: bool = False,
        logger: Optional[Any] = None
) -> str:
    """
    ä»æ–‡æœ¬ç”Ÿæˆè¯­éŸ³ï¼ˆæ”¯æŒæ–‡ä»¶è·¯å¾„æˆ–ç›´æ¥æ–‡æœ¬ï¼‰
    
    Args:
        input_text: è¾“å…¥æ–‡æœ¬æˆ–æ–‡æœ¬æ–‡ä»¶è·¯å¾„
        language: ç›®æ ‡è¯­è¨€ä»£ç ï¼ˆå¦‚ 'en', 'zh', 'fr' ç­‰ï¼‰
        video_sample: è§†é¢‘æ ·æœ¬è·¯å¾„ï¼ˆç”¨äºæå–å‚è€ƒéŸ³é¢‘è¿›è¡Œè¯­éŸ³å…‹éš†ï¼‰
        model_name: TTS æ¨¡å‹åç§°ï¼Œå¦‚æœä¸º None åˆ™è‡ªåŠ¨é€‰æ‹©
        output_path: è¾“å‡ºéŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸º None åˆ™è‡ªåŠ¨ç”Ÿæˆ
        device: è®¾å¤‡ç±»å‹ï¼Œ'cpu' æˆ– 'cuda'
        prefer_multilingual: æ˜¯å¦ä¼˜å…ˆä½¿ç”¨å¤šè¯­è¨€æ¨¡å‹ï¼ˆé»˜è®¤ Falseï¼‰
        logger: æ—¥å¿—è®°å½•å™¨ï¼ˆå¯é€‰ï¼‰ï¼Œå¦‚æœæä¾›åˆ™ä½¿ç”¨æ—¥å¿—è¾“å‡ºï¼Œå¦åˆ™ä½¿ç”¨ print
    
    Returns:
        è¾“å‡ºéŸ³é¢‘æ–‡ä»¶è·¯å¾„
    """

    # å®šä¹‰è¾“å‡ºå‡½æ•°ï¼šå¦‚æœæœ‰ logger åˆ™ä½¿ç”¨ loggerï¼Œå¦åˆ™ä½¿ç”¨ print
    def log_info(msg: str):
        if logger:
            logger.info(msg)
        else:
            print(msg)

    def log_error(msg: str):
        if logger:
            logger.error(msg)
        else:
            print(msg)

    def log_warning(msg: str):
        if logger:
            logger.warning(msg)
        else:
            print(msg)

    # è·å–æ–‡æœ¬å†…å®¹ï¼ˆè‡ªåŠ¨è¯†åˆ«æ˜¯æ–‡ä»¶è¿˜æ˜¯ç›´æ¥æ–‡æœ¬ï¼‰
    try:
        text = get_text_from_input(input_text)
        log_info(f"âœ… æ–‡æœ¬å‡†å¤‡å®Œæˆï¼Œå…± {len(text)} ä¸ªå­—ç¬¦")
    except Exception as e:
        log_error(f"âŒ è·å–æ–‡æœ¬å¤±è´¥: {e}")
        raise

    # ç¡®å®šè¾“å‡ºè·¯å¾„
    if output_path is None:
        # å¦‚æœè¾“å…¥æ˜¯æ–‡ä»¶è·¯å¾„ï¼ŒåŸºäºæ–‡ä»¶åç”Ÿæˆè¾“å‡º
        input_path = Path(input_text)
        if input_path.exists() and input_path.is_file():
            output_path = str(input_path.parent / f"{input_path.stem}_tts_{language}.wav")
        else:
            # å¦‚æœæ˜¯ç›´æ¥æ–‡æœ¬ï¼Œç”Ÿæˆé»˜è®¤æ–‡ä»¶å
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = f"output_tts_{language}_{timestamp}.wav"
    else:
        output_path = str(Path(output_path))

    # è·å–å‚è€ƒéŸ³é¢‘ï¼ˆä»…æ”¯æŒéŸ³é¢‘æ–‡ä»¶ï¼‰
    reference_audio = None
    if video_sample:
        try:
            reference_audio = get_reference_audio(video_sample, logger=logger)
            log_info(f"âœ… å‚è€ƒéŸ³é¢‘å‡†å¤‡å®Œæˆ")
        except Exception as e:
            log_error(f"âŒ è·å–å‚è€ƒéŸ³é¢‘å¤±è´¥: {e}")
            raise

    # åˆå§‹åŒ– TTS æ¨¡å‹
    if model_name is None:
        get_available_models_by_language(language)
        model_name = select_model(language, prefer_multilingual=prefer_multilingual)

    log_info(f"ğŸ¤– æ­£åœ¨åˆå§‹åŒ– TTS æ¨¡å‹: {model_name}")
    try:
        tts = TTS(model_name=model_name, progress_bar=True)
        log_info("ğŸ“¥ æ¨¡å‹åŠ è½½ä¸­...")
        tts.to(device)
        log_info(f"ğŸ“¦ æ¨¡å‹å·²ç§»åŠ¨åˆ°è®¾å¤‡: {device}")
    except Exception as e:
        log_error(f"âŒ TTS æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        log_warning("ğŸ’¡ æç¤º: å°è¯•ä½¿ç”¨å…¶ä»–æ¨¡å‹æˆ–æ£€æŸ¥ç½‘ç»œè¿æ¥")
        raise

    log_info("âœ… TTS æ¨¡å‹åŠ è½½å®Œæˆ")

    # ç”Ÿæˆè¯­éŸ³
    log_info(f"ğŸ¤ æ­£åœ¨ç”Ÿæˆè¯­éŸ³ (è¯­è¨€: {language}, æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦)...")

    import time
    start_time = time.time()

    try:
        # ç®€åŒ–é€»è¾‘ï¼šç»Ÿä¸€è°ƒç”¨ tts_to_fileï¼Œè®©å®ƒè‡ªå·±å¤„ç†å‚æ•°
        kwargs = {
            'text': text,
            'file_path': output_path
        }
        # å¦‚æœæ˜¯å¤šè¯­è¨€æ¨¡å‹ï¼Œæ·»åŠ è¯­è¨€å‚æ•°
        is_multilingual = ("xtts" in model_name.lower() or
                           "your_tts" in model_name.lower() or
                           (hasattr(tts, 'is_multi_lingual') and tts.is_multi_lingual))

        if is_multilingual:
            kwargs['language'] = language
            log_info(f"ğŸŒ ä½¿ç”¨å¤šè¯­è¨€æ¨¡å‹ï¼Œè¯­è¨€: {language}")

        # å¦‚æœæä¾›äº†å‚è€ƒéŸ³é¢‘ï¼Œæ·»åŠ  speaker_wav å‚æ•°
        if reference_audio:
            kwargs['speaker_wav'] = reference_audio
            log_info(f"ğŸ¯ ä½¿ç”¨å‚è€ƒéŸ³é¢‘è¿›è¡Œè¯­éŸ³å…‹éš†: {reference_audio}")

        log_info("ğŸ”„ å¼€å§‹è¯­éŸ³åˆæˆ...")
        tts.tts_to_file(**kwargs)

        elapsed_time = time.time() - start_time
        log_info(f"â±ï¸  è¯­éŸ³åˆæˆè€—æ—¶: {elapsed_time:.2f} ç§’")

    except Exception as e:
        log_error(f"âŒ è¯­éŸ³ç”Ÿæˆå¤±è´¥: {e}")
        raise

    log_info(f"âœ… è¯­éŸ³ç”Ÿæˆå®Œæˆ: {output_path}")
    return output_path


def main():
    parser = argparse.ArgumentParser(
        description="TTS è¯­éŸ³ç”Ÿæˆå·¥å…· - ä»æ–‡æœ¬æˆ–æ–‡æœ¬æ–‡ä»¶ç”ŸæˆæŒ‡å®šè¯­è¨€çš„è¯­éŸ³",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # åŸºæœ¬ä½¿ç”¨ï¼šç›´æ¥è¾“å…¥æ–‡æœ¬
  python video_tts.py --input "Hello world" --language en --output output.wav
  
  # ä»æ–‡æœ¬æ–‡ä»¶ç”Ÿæˆè¯­éŸ³
  python video_tts.py --input text.txt --language en --output output.wav
  
  # ä½¿ç”¨éŸ³é¢‘æ ·æœ¬è¿›è¡Œè¯­éŸ³å…‹éš†ï¼ˆç›´æ¥æ–‡æœ¬ï¼‰
  uv run video_tts.py --input "æ­å–œæ­å–œ" --language zh --video-sample audio.wav --output output.wav
  
  # ä½¿ç”¨æŒ‡å®šçš„ TTS æ¨¡å‹
  python video_tts.py --input "Hello world" --language en --model tts_models/multilingual/multi-dataset/xtts_v2
  
  # ä½¿ç”¨ GPU åŠ é€Ÿ
  python video_tts.py --input "Hello world" --language en --device cuda --output output.wav
        """
    )

    parser.add_argument("--input", "-i", type=str, required=True,
                        help="è¾“å…¥æ–‡æœ¬æˆ–æ–‡æœ¬æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœè·¯å¾„å­˜åœ¨åˆ™è¯»å–æ–‡ä»¶ï¼Œå¦åˆ™ä½œä¸ºæ–‡æœ¬ä½¿ç”¨ï¼‰")
    parser.add_argument("--language", "-l", type=str, required=True, help="ç›®æ ‡è¯­è¨€ä»£ç  (å¦‚: en, zh, fr, de ç­‰)")
    parser.add_argument("--video-sample", "-v", type=str, default=None,
                        help="éŸ³é¢‘æ ·æœ¬è·¯å¾„ï¼ˆå¯é€‰ï¼Œç”¨äºè¯­éŸ³å…‹éš†ã€‚æ”¯æŒéŸ³é¢‘æ–‡ä»¶ï¼š.wav, .mp3, .flac, .m4a, .aac, .ogg, .opus ç­‰ï¼‰")
    parser.add_argument("--model", "-m", type=str, default=None, help="TTS æ¨¡å‹åç§°ï¼Œå¦‚æœæœªæŒ‡å®šåˆ™æ ¹æ®è¯­è¨€è‡ªåŠ¨é€‰æ‹©")
    parser.add_argument("--output", "-o", type=str, default=None, help="è¾“å‡ºéŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆ.wavï¼‰ï¼Œå¦‚æœæœªæŒ‡å®šåˆ™è‡ªåŠ¨ç”Ÿæˆ")
    parser.add_argument("--device", type=str, default="cpu", choices=["cpu", "cuda"], help="è®¾å¤‡ç±»å‹ (cpu æˆ– cuda)")
    parser.add_argument("--prefer-multilingual", action="store_true",
                        help="ä¼˜å…ˆä½¿ç”¨å¤šè¯­è¨€æ¨¡å‹ï¼ˆXTTS v2ï¼‰ã€‚é»˜è®¤ä¼˜å…ˆä½¿ç”¨ç¨³å®šçš„å•è¯­è¨€æ¨¡å‹")

    args = parser.parse_args()

    try:
        output_path = generate_speech(
            input_text=args.input,
            language=args.language,
            video_sample=args.video_sample,
            model_name=args.model,
            output_path=args.output,
            device=args.device,
            prefer_multilingual=args.prefer_multilingual
        )

        print(f"\nğŸ‰ å¤„ç†å®Œæˆï¼")
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_path}")
        sys.exit(0)

    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
