#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TTS è¯­éŸ³ç”Ÿæˆå·¥å…·

ä»æ–‡æœ¬æ–‡ä»¶è¯»å–å†…å®¹ï¼Œä½¿ç”¨ TTS æ¨¡å‹ç”ŸæˆæŒ‡å®šè¯­è¨€çš„è¯­éŸ³ã€‚
æ”¯æŒä»è§†é¢‘æ ·æœ¬ä¸­æå–éŸ³é¢‘ä½œä¸ºå‚è€ƒè¿›è¡Œè¯­éŸ³å…‹éš†ã€‚
"""

import argparse
import shutil
import sys
import tempfile
from pathlib import Path
from typing import Optional, Any

try:
    from moviepy.editor import VideoFileClip
    MOVIEPY_AVAILABLE = True
except ImportError:
    MOVIEPY_AVAILABLE = False

try:
    import ffmpeg
    FFMPEG_AVAILABLE = True
except ImportError:
    FFMPEG_AVAILABLE = False

from TTS.api import TTS


def get_reference_audio(audio_or_video_path: str, output_audio_path: str, logger: Optional[Any] = None) -> str:
    """
    è·å–å‚è€ƒéŸ³é¢‘ï¼Œæ”¯æŒç›´æ¥éŸ³é¢‘æ–‡ä»¶æˆ–ä»è§†é¢‘ä¸­æå–
    
    Args:
        audio_or_video_path: éŸ³é¢‘æ–‡ä»¶æˆ–è§†é¢‘æ–‡ä»¶è·¯å¾„
        output_audio_path: è¾“å‡ºéŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆä»…å½“éœ€è¦ä»è§†é¢‘æå–æ—¶ä½¿ç”¨ï¼‰
    
    Returns:
        å‚è€ƒéŸ³é¢‘æ–‡ä»¶è·¯å¾„
    """
    path = Path(audio_or_video_path)
    if not path.exists():
        raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {path}")
    
    # æ”¯æŒçš„éŸ³é¢‘æ ¼å¼
    audio_extensions = {'.wav', '.mp3', '.flac', '.m4a', '.aac', '.ogg', '.opus'}
    # å¸¸è§çš„è§†é¢‘æ ¼å¼
    video_extensions = {'.mp4', '.avi', '.mov', '.mkv', '.webm', '.flv', '.m4v'}
    
    file_ext = path.suffix.lower()
    
    # å®šä¹‰è¾“å‡ºå‡½æ•°
    def log_info(msg: str):
        if logger:
            logger.info(msg)
        else:
            print(msg)
    
    # å¦‚æœæ˜¯éŸ³é¢‘æ–‡ä»¶ï¼Œç›´æ¥è¿”å›
    if file_ext in audio_extensions:
        log_info(f"ğŸµ æ£€æµ‹åˆ°éŸ³é¢‘æ–‡ä»¶ï¼Œç›´æ¥ä½¿ç”¨: {path}")
        return str(path)
    
    # å¦‚æœæ˜¯è§†é¢‘æ–‡ä»¶ï¼Œéœ€è¦æå–éŸ³é¢‘
    if file_ext in video_extensions:
        log_info(f"ğŸ“¹ æ£€æµ‹åˆ°è§†é¢‘æ–‡ä»¶ï¼Œæ­£åœ¨æå–éŸ³é¢‘: {path}")
        if MOVIEPY_AVAILABLE:
            video = VideoFileClip(str(path))
            audio = video.audio
            if audio is None:
                video.close()
                raise ValueError("è§†é¢‘æ–‡ä»¶ä¸­æ²¡æœ‰éŸ³é¢‘è½¨é“")
            audio.write_audiofile(output_audio_path, verbose=False, logger=None)
            video.close()
            audio.close()
            return output_audio_path
        elif FFMPEG_AVAILABLE:
            try:
                (
                    ffmpeg
                    .input(str(path))
                    .output(output_audio_path, acodec='pcm_s16le', ac=1, ar='22050')
                    .overwrite_output()
                    .run(capture_stdout=True, capture_stderr=True, quiet=True)
                )
                return output_audio_path
            except ffmpeg.Error as e:
                raise RuntimeError(f"FFmpeg é”™è¯¯: {e.stderr.decode()}")
        else:
            raise ImportError("éœ€è¦å®‰è£… moviepy æˆ– ffmpeg-python æ¥ä»è§†é¢‘æå–éŸ³é¢‘")
    
    # æœªçŸ¥æ ¼å¼ï¼Œå°è¯•ä½œä¸ºéŸ³é¢‘æ–‡ä»¶å¤„ç†
    log_info(f"âš ï¸  æœªçŸ¥æ–‡ä»¶æ ¼å¼ ({file_ext})ï¼Œå°è¯•ä½œä¸ºéŸ³é¢‘æ–‡ä»¶ä½¿ç”¨: {path}")
    return str(path)


def get_text_from_input(input_str: str) -> str:
    """
    ä»è¾“å…¥è·å–æ–‡æœ¬ï¼Œæ”¯æŒæ–‡ä»¶è·¯å¾„æˆ–ç›´æ¥æ–‡æœ¬
    
    Args:
        input_str: æ–‡ä»¶è·¯å¾„æˆ–ç›´æ¥æ–‡æœ¬å†…å®¹
    
    Returns:
        æ–‡æœ¬å†…å®¹
    """
    input_path = Path(input_str)
    
    # å¦‚æœè¾“å…¥æ˜¯å­˜åœ¨çš„æ–‡ä»¶è·¯å¾„ï¼Œåˆ™ä»æ–‡ä»¶è¯»å–
    if input_path.exists() and input_path.is_file():
        # æ³¨æ„ï¼šget_text_from_input æ²¡æœ‰ logger å‚æ•°ï¼Œä¿æŒ print
        print(f"ğŸ“„ æ£€æµ‹åˆ°æ–‡ä»¶è·¯å¾„ï¼Œæ­£åœ¨è¯»å–: {input_path}")
        for encoding in ('utf-8', 'gbk'):
            try:
                with open(input_path, 'r', encoding=encoding) as f:
                    text = f.read().strip()
                if not text:
                    raise ValueError(f"æ–‡æœ¬æ–‡ä»¶ä¸ºç©º: {input_path}")
                return text
            except UnicodeDecodeError:
                continue
        raise ValueError(f"æ— æ³•è¯»å–æ–‡æœ¬æ–‡ä»¶ï¼Œè¯·ç¡®ä¿æ–‡ä»¶ä½¿ç”¨ UTF-8 æˆ– GBK ç¼–ç : {input_path}")
    else:
        # å¦åˆ™ç›´æ¥ä½œä¸ºæ–‡æœ¬ä½¿ç”¨
        text = input_str.strip()
        if not text:
            raise ValueError("è¾“å…¥çš„æ–‡æœ¬ä¸èƒ½ä¸ºç©º")
        return text


def get_available_models_by_language(language: str) -> list:
    """
    ä½¿ç”¨ TTS API åŠ¨æ€æŸ¥è¯¢æŒ‡å®šè¯­è¨€çš„å¯ç”¨æ¨¡å‹
    
    Args:
        language: è¯­è¨€ä»£ç ï¼ˆå¦‚ 'en', 'zh', 'ja', 'es' ç­‰ï¼‰
    
    Returns:
        list: è¯¥è¯­è¨€çš„å¯ç”¨æ¨¡å‹åˆ—è¡¨ï¼Œæ ¼å¼ä¸º ['tts_models/lang/dataset/model', ...]
    """
    try:
        from TTS.api import TTS
        tts = TTS()
        manager = tts.list_models()
        all_models = manager.list_tts_models()
        
        # æŸ¥æ‰¾åŒ¹é…è¯­è¨€çš„æ¨¡å‹
        lang_lower = language.lower()
        # è¯­è¨€ä»£ç æ˜ å°„ï¼ˆæ ‡å‡†åŒ–ï¼‰
        lang_map = {
            'zh': 'zh-CN',
            'chinese': 'zh-CN',
            'cn': 'zh-CN',
        }
        normalized_lang = lang_map.get(lang_lower, lang_lower)
        
        # è¿‡æ»¤å‡ºè¯¥è¯­è¨€çš„æ¨¡å‹
        matching_models = [
            model for model in all_models
            if isinstance(model, str) and f'/{normalized_lang}/' in model or f'/{lang_lower}/' in model
        ]
        
        return matching_models if matching_models else []
    except Exception:
        return []


def select_model(language: str, use_dynamic_query: bool = False) -> str:
    """
    æ ¹æ®è¯­è¨€è‡ªåŠ¨é€‰æ‹©æ¨¡å‹
    
    XTTS v2 æ”¯æŒçš„è¯­è¨€ï¼ˆ17ç§ï¼‰ï¼š
    en (English), es (Spanish), fr (French), de (German), it (Italian),
    pt (Portuguese), pl (Polish), tr (Turkish), ru (Russian), nl (Dutch),
    cs (Czech), ar (Arabic), zh-cn (Chinese), ja (Japanese), hu (Hungarian), ko (Korean)
    
    å¯¹äºæœ‰å•è¯­è¨€æ¨¡å‹çš„ï¼Œä¼˜å…ˆä½¿ç”¨å•è¯­è¨€æ¨¡å‹ï¼›å¦åˆ™ä½¿ç”¨ XTTS v2 å¤šè¯­è¨€æ¨¡å‹
    
    Args:
        language: è¯­è¨€ä»£ç 
        use_dynamic_query: æ˜¯å¦ä½¿ç”¨ TTS API åŠ¨æ€æŸ¥è¯¢ï¼ˆé»˜è®¤ Falseï¼Œä½¿ç”¨é¢„å®šä¹‰æ˜ å°„ï¼‰
    
    Returns:
        str: æ¨¡å‹åç§°ï¼Œæ ¼å¼ä¸º 'tts_models/lang/dataset/model'
    """
    lang_lower = language.lower()
    
    # å¦‚æœå¯ç”¨åŠ¨æ€æŸ¥è¯¢ï¼Œå°è¯•ä» TTS API è·å–æ¨¡å‹
    if use_dynamic_query:
        available_models = get_available_models_by_language(language)
        if available_models:
            # ä¼˜å…ˆé€‰æ‹© tacotron2-DDC ç±»å‹çš„æ¨¡å‹ï¼Œå¦åˆ™é€‰æ‹©ç¬¬ä¸€ä¸ª
            preferred = [m for m in available_models if 'tacotron2-DDC' in m]
            if preferred:
                return preferred[0]
            return available_models[0]
    
    # å•è¯­è¨€æ¨¡å‹æ˜ å°„ï¼ˆå¦‚æœæœ‰å¯¹åº”çš„å•è¯­è¨€æ¨¡å‹ï¼Œä¼˜å…ˆä½¿ç”¨ï¼‰
    model_map = {
        # ä¸­æ–‡
        'zh': "tts_models/zh-CN/baker/tacotron2-DDC-GST",
        'chinese': "tts_models/zh-CN/baker/tacotron2-DDC-GST",
        'cn': "tts_models/zh-CN/baker/tacotron2-DDC-GST",
        'zh-cn': "tts_models/zh-CN/baker/tacotron2-DDC-GST",
        # è‹±æ–‡
        'en': "tts_models/en/ljspeech/tacotron2-DDC",
        'english': "tts_models/en/ljspeech/tacotron2-DDC",
        # æ³•è¯­
        'fr': "tts_models/fr/mai/tacotron2-DDC",
        'french': "tts_models/fr/mai/tacotron2-DDC",
        # å¾·è¯­
        'de': "tts_models/de/thorsten/tacotron2-DDC",
        'german': "tts_models/de/thorsten/tacotron2-DDC",
        # è¥¿ç­ç‰™è¯­ - æœ‰å•è¯­è¨€æ¨¡å‹å¯ç”¨
        'es': "tts_models/es/mai/tacotron2-DDC",
        'spanish': "tts_models/es/mai/tacotron2-DDC",
        'espaÃ±ol': "tts_models/es/mai/tacotron2-DDC",
        # æ—¥è¯­ - æœ‰å•è¯­è¨€æ¨¡å‹å¯ç”¨
        'ja': "tts_models/ja/kokoro/tacotron2-DDC",
        'japanese': "tts_models/ja/kokoro/tacotron2-DDC",
        # å…¶ä»– XTTS v2 æ”¯æŒçš„è¯­è¨€
        'it': "tts_models/multilingual/multi-dataset/xtts_v2",  # Italian
        'italian': "tts_models/multilingual/multi-dataset/xtts_v2",
        'pt': "tts_models/multilingual/multi-dataset/xtts_v2",  # Portuguese
        'portuguese': "tts_models/multilingual/multi-dataset/xtts_v2",
        'pl': "tts_models/multilingual/multi-dataset/xtts_v2",  # Polish
        'polish': "tts_models/multilingual/multi-dataset/xtts_v2",
        'tr': "tts_models/multilingual/multi-dataset/xtts_v2",  # Turkish
        'turkish': "tts_models/multilingual/multi-dataset/xtts_v2",
        'ru': "tts_models/multilingual/multi-dataset/xtts_v2",  # Russian
        'russian': "tts_models/multilingual/multi-dataset/xtts_v2",
        'nl': "tts_models/multilingual/multi-dataset/xtts_v2",  # Dutch
        'dutch': "tts_models/multilingual/multi-dataset/xtts_v2",
        'cs': "tts_models/multilingual/multi-dataset/xtts_v2",  # Czech
        'czech': "tts_models/multilingual/multi-dataset/xtts_v2",
        'ar': "tts_models/multilingual/multi-dataset/xtts_v2",  # Arabic
        'arabic': "tts_models/multilingual/multi-dataset/xtts_v2",
        'hu': "tts_models/multilingual/multi-dataset/xtts_v2",  # Hungarian
        'hungarian': "tts_models/multilingual/multi-dataset/xtts_v2",
        'ko': "tts_models/multilingual/multi-dataset/xtts_v2",  # Korean
        'korean': "tts_models/multilingual/multi-dataset/xtts_v2",
    }
    
    # å¦‚æœæ‰¾åˆ°åŒ¹é…çš„æ¨¡å‹ï¼Œè¿”å›å®ƒï¼›å¦åˆ™é»˜è®¤ä½¿ç”¨ XTTS v2
    return model_map.get(lang_lower, "tts_models/multilingual/multi-dataset/xtts_v2")


def generate_speech(
    input_text: str,
    language: str,
    video_sample: Optional[str] = None,
    model_name: Optional[str] = None,
    output_path: Optional[str] = None,
    device: str = "cpu",
    logger: Optional[Any] = None
) -> str:
    """
    ä»æ–‡æœ¬ç”Ÿæˆè¯­éŸ³ï¼ˆæ”¯æŒæ–‡ä»¶è·¯å¾„æˆ–ç›´æ¥æ–‡æœ¬ï¼‰
    
    Args:
        input_text: è¾“å…¥æ–‡æœ¬æˆ–æ–‡æœ¬æ–‡ä»¶è·¯å¾„
        language: ç›®æ ‡è¯­è¨€ä»£ç ï¼ˆå¦‚ 'en', 'zh', 'fr' ç­‰ï¼‰
        video_sample: è§†é¢‘æ ·æœ¬è·¯å¾„ï¼ˆç”¨äºæå–å‚è€ƒéŸ³é¢‘è¿›è¡Œè¯­éŸ³å…‹éš†ï¼‰
        model_name: TTS æ¨¡å‹åç§°ï¼Œå¦‚æœä¸º None åˆ™è‡ªåŠ¨é€‰æ‹©
        output_path: è¾“å‡ºéŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸º None åˆ™è‡ªåŠ¨ç”Ÿæˆ
        device: è®¾å¤‡ç±»å‹ï¼Œ'cpu' æˆ– 'cuda'
    logger: æ—¥å¿—è®°å½•å™¨ï¼ˆå¯é€‰ï¼‰ï¼Œå¦‚æœæä¾›åˆ™ä½¿ç”¨æ—¥å¿—è¾“å‡ºï¼Œå¦åˆ™ä½¿ç”¨ print
    
    Returns:
        è¾“å‡ºéŸ³é¢‘æ–‡ä»¶è·¯å¾„
    """
    # å®šä¹‰è¾“å‡ºå‡½æ•°ï¼šå¦‚æœæœ‰ logger åˆ™ä½¿ç”¨ loggerï¼Œå¦åˆ™ä½¿ç”¨ print
    def log_info(msg: str):
        if logger:
            logger.info(msg)
        else:
            print(msg)
    
    def log_error(msg: str):
        if logger:
            logger.error(msg)
        else:
            print(msg)
    
    def log_warning(msg: str):
        if logger:
            logger.warning(msg)
        else:
            print(msg)
    
    # è·å–æ–‡æœ¬å†…å®¹ï¼ˆè‡ªåŠ¨è¯†åˆ«æ˜¯æ–‡ä»¶è¿˜æ˜¯ç›´æ¥æ–‡æœ¬ï¼‰
    try:
        text = get_text_from_input(input_text)
        log_info(f"âœ… æ–‡æœ¬å‡†å¤‡å®Œæˆï¼Œå…± {len(text)} ä¸ªå­—ç¬¦")
    except Exception as e:
        log_error(f"âŒ è·å–æ–‡æœ¬å¤±è´¥: {e}")
        raise
    
    # ç¡®å®šè¾“å‡ºè·¯å¾„
    if output_path is None:
        # å¦‚æœè¾“å…¥æ˜¯æ–‡ä»¶è·¯å¾„ï¼ŒåŸºäºæ–‡ä»¶åç”Ÿæˆè¾“å‡º
        input_path = Path(input_text)
        if input_path.exists() and input_path.is_file():
            output_path = str(input_path.parent / f"{input_path.stem}_tts_{language}.wav")
        else:
            # å¦‚æœæ˜¯ç›´æ¥æ–‡æœ¬ï¼Œç”Ÿæˆé»˜è®¤æ–‡ä»¶å
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = f"output_tts_{language}_{timestamp}.wav"
    else:
        output_path = str(Path(output_path))
    
    # è·å–å‚è€ƒéŸ³é¢‘ï¼ˆæ”¯æŒç›´æ¥éŸ³é¢‘æ–‡ä»¶æˆ–ä»è§†é¢‘æå–ï¼‰
    reference_audio = None
    if video_sample:
        # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶ä¿å­˜æå–çš„éŸ³é¢‘ï¼ˆå¦‚æœéœ€è¦ï¼‰ï¼Œç¡®ä¿åœ¨ TTS ä½¿ç”¨å‰ä¸è¢«åˆ é™¤
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_audio:
            extracted_audio_path = tmp_audio.name
        
        try:
            reference_audio = get_reference_audio(video_sample, extracted_audio_path, logger=logger)
            log_info(f"âœ… å‚è€ƒéŸ³é¢‘å‡†å¤‡å®Œæˆ")
        except Exception as e:
            log_error(f"âŒ è·å–å‚è€ƒéŸ³é¢‘å¤±è´¥: {e}")
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            Path(extracted_audio_path).unlink(missing_ok=True)
            raise
    
    # åˆå§‹åŒ– TTS æ¨¡å‹
    if model_name is None:
        model_name = select_model(language)
    
    log_info(f"ğŸ¤– æ­£åœ¨åˆå§‹åŒ– TTS æ¨¡å‹: {model_name}")
    try:
        tts = TTS(model_name=model_name, progress_bar=True)
        log_info(f"ğŸ“¥ æ¨¡å‹åŠ è½½ä¸­...")
        tts.to(device)
        log_info(f"ğŸ“¦ æ¨¡å‹å·²ç§»åŠ¨åˆ°è®¾å¤‡: {device}")
    except Exception as e:
        log_error(f"âŒ TTS æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        log_warning("ğŸ’¡ æç¤º: å°è¯•ä½¿ç”¨å…¶ä»–æ¨¡å‹æˆ–æ£€æŸ¥ç½‘ç»œè¿æ¥")
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if reference_audio:
            Path(reference_audio).unlink(missing_ok=True)
        raise
    
    log_info(f"âœ… TTS æ¨¡å‹åŠ è½½å®Œæˆ")
    
    # ç”Ÿæˆè¯­éŸ³
    log_info(f"ğŸ¤ æ­£åœ¨ç”Ÿæˆè¯­éŸ³ (è¯­è¨€: {language}, æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦)...")
    
    import time
    start_time = time.time()
    
    try:
        # ç®€åŒ–é€»è¾‘ï¼šç»Ÿä¸€è°ƒç”¨ tts_to_fileï¼Œè®©å®ƒè‡ªå·±å¤„ç†å‚æ•°
        kwargs = {
            'text': text,
            'file_path': output_path
        }
        
        # å¦‚æœæ˜¯å¤šè¯­è¨€æ¨¡å‹ï¼Œæ·»åŠ è¯­è¨€å‚æ•°
        is_multilingual = ("xtts" in model_name.lower() or 
                         "your_tts" in model_name.lower() or
                         (hasattr(tts, 'is_multi_lingual') and tts.is_multi_lingual))
        
        if is_multilingual:
            kwargs['language'] = language
            log_info(f"ğŸŒ ä½¿ç”¨å¤šè¯­è¨€æ¨¡å‹ï¼Œè¯­è¨€: {language}")
        
        # å¦‚æœæä¾›äº†å‚è€ƒéŸ³é¢‘ï¼Œæ·»åŠ  speaker_wav å‚æ•°
        if reference_audio:
            kwargs['speaker_wav'] = reference_audio
            log_info(f"ğŸ¯ ä½¿ç”¨å‚è€ƒéŸ³é¢‘è¿›è¡Œè¯­éŸ³å…‹éš†: {reference_audio}")
        
        log_info(f"ğŸ”„ å¼€å§‹è¯­éŸ³åˆæˆ...")
        tts.tts_to_file(**kwargs)
        
        elapsed_time = time.time() - start_time
        log_info(f"â±ï¸  è¯­éŸ³åˆæˆè€—æ—¶: {elapsed_time:.2f} ç§’")
        
    except Exception as e:
        log_error(f"âŒ è¯­éŸ³ç”Ÿæˆå¤±è´¥: {e}")
        raise
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆä»…å½“æ˜¯ä»è§†é¢‘æå–çš„éŸ³é¢‘æ—¶ï¼‰
        if reference_audio and Path(reference_audio).exists():
            # æ£€æŸ¥æ˜¯å¦æ˜¯ä¸´æ—¶æ–‡ä»¶ï¼ˆé€šè¿‡è·¯å¾„æ˜¯å¦åŒ…å«ä¸´æ—¶ç›®å½•ç‰¹å¾åˆ¤æ–­ï¼‰
            try:
                if 'tmp' in reference_audio.lower() or tempfile.gettempdir() in reference_audio:
                    Path(reference_audio).unlink(missing_ok=True)
            except Exception:
                pass  # å¿½ç•¥æ¸…ç†é”™è¯¯
    
    log_info(f"âœ… è¯­éŸ³ç”Ÿæˆå®Œæˆ: {output_path}")
    return output_path


def main():
    parser = argparse.ArgumentParser(
        description="TTS è¯­éŸ³ç”Ÿæˆå·¥å…· - ä»æ–‡æœ¬æˆ–æ–‡æœ¬æ–‡ä»¶ç”ŸæˆæŒ‡å®šè¯­è¨€çš„è¯­éŸ³",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # åŸºæœ¬ä½¿ç”¨ï¼šç›´æ¥è¾“å…¥æ–‡æœ¬
  python video_tts.py --input "Hello world" --language en --output output.wav
  
  # ä»æ–‡æœ¬æ–‡ä»¶ç”Ÿæˆè¯­éŸ³
  python video_tts.py --input text.txt --language en --output output.wav
  
  # ä½¿ç”¨éŸ³é¢‘/è§†é¢‘æ ·æœ¬è¿›è¡Œè¯­éŸ³å…‹éš†ï¼ˆç›´æ¥æ–‡æœ¬ï¼‰
  uv run video_tts.py --input "æ­å–œæ­å–œ" --language zh --video-sample audio.wav --output output.wav
  uv run video_tts.py --input "æ­å–œæ­å–œ" --language zh --video-sample sample.mp4 --output output.wav
  
  # ä½¿ç”¨æŒ‡å®šçš„ TTS æ¨¡å‹
  python video_tts.py --input "Hello world" --language en --model tts_models/multilingual/multi-dataset/xtts_v2
  
  # ä½¿ç”¨ GPU åŠ é€Ÿ
  python video_tts.py --input "Hello world" --language en --device cuda --output output.wav
        """
    )
    
    parser.add_argument("--input", "-i", type=str, required=True, help="è¾“å…¥æ–‡æœ¬æˆ–æ–‡æœ¬æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœè·¯å¾„å­˜åœ¨åˆ™è¯»å–æ–‡ä»¶ï¼Œå¦åˆ™ä½œä¸ºæ–‡æœ¬ä½¿ç”¨ï¼‰")
    parser.add_argument("--language", "-l", type=str, required=True, help="ç›®æ ‡è¯­è¨€ä»£ç  (å¦‚: en, zh, fr, de ç­‰)")
    parser.add_argument("--video-sample", "-v", type=str, default=None, help="éŸ³é¢‘æˆ–è§†é¢‘æ ·æœ¬è·¯å¾„ï¼ˆå¯é€‰ï¼Œç”¨äºè¯­éŸ³å…‹éš†ã€‚æ”¯æŒéŸ³é¢‘æ–‡ä»¶ï¼š.wav, .mp3, .flac ç­‰ï¼›è§†é¢‘æ–‡ä»¶ï¼š.mp4, .avi, .mov ç­‰ï¼‰")
    parser.add_argument("--model", "-m", type=str, default=None, help="TTS æ¨¡å‹åç§°ï¼Œå¦‚æœæœªæŒ‡å®šåˆ™æ ¹æ®è¯­è¨€è‡ªåŠ¨é€‰æ‹©")
    parser.add_argument("--output", "-o", type=str, default=None, help="è¾“å‡ºéŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆ.wavï¼‰ï¼Œå¦‚æœæœªæŒ‡å®šåˆ™è‡ªåŠ¨ç”Ÿæˆ")
    parser.add_argument("--device", type=str, default="cpu", choices=["cpu", "cuda"], help="è®¾å¤‡ç±»å‹ (cpu æˆ– cuda)")
    
    args = parser.parse_args()
    
    try:
        output_path = generate_speech(
            input_text=args.input,
            language=args.language,
            video_sample=args.video_sample,
            model_name=args.model,
            output_path=args.output,
            device=args.device
        )
        
        print(f"\nğŸ‰ å¤„ç†å®Œæˆï¼")
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_path}")
        sys.exit(0)
    
    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
